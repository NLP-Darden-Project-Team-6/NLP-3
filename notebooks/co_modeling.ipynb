{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import main\n",
    "from model import model_data\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test = model_data('../data/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len = len((X_train + X_validate + X_test))\n",
    "train_len = X_train.shape[0]\n",
    "validate_len = X_validate.shape[0]\n",
    "test_len = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Size: {train_len / dataset_len:.2%}\")\n",
    "print(f\"Validate Size: {validate_len / dataset_len:.2%}\")\n",
    "print(f\"Test Size: {test_len / dataset_len:.2%}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Total {(train_len + validate_len + test_len) / dataset_len:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_prediction = y_train.value_counts().nlargest(1).index[0]\n",
    "\n",
    "baseline_accuracy = (y_train == baseline_prediction).mean()\n",
    "print(f\"The baseline accuracy is {baseline_accuracy:.0%}\")\n",
    "print(f\"{baseline_prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_params = {'learning_rate': [0.0001, 0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ridge Classifier\n",
    "\n",
    "clf = RidgeClassifierCV()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "tree = RandomForestClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_train, y_train)\n",
    "\n",
    "### Gradient Boost\n",
    "\n",
    "ml = GridSearchCV(GradientBoostingClassifier(), boost_params, cv=5)\n",
    "ml.fit(X_train, y_train)\n",
    "ml.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set\n",
    "\n",
    "The best 3 models from the training set.\n",
    "\n",
    "1. Ridge Classifier \n",
    "1. Random Forest\n",
    "1. Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ridge Classifier\n",
    "\n",
    "clf.score(X_validate, y_validate)\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "tree.score(X_validate, y_validate)\n",
    "\n",
    "### Gradient Boost\n",
    "\n",
    "ml.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8aa94cf008a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## 1. Gradient Boost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ml' is not defined"
     ]
    }
   ],
   "source": [
    "## Test Set\n",
    "## 1. Gradient Boost\n",
    "\n",
    "ml.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "train['predicted'] = ml.predict(X_train)\n",
    "validate['predicted'] = ml.predict(X_validate)\n",
    "test['predicted'] = ml.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Training Set\")\n",
    "print(\"\")\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation Set\")\n",
    "print(\"\")\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Test Set\")\n",
    "print(\"\")\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

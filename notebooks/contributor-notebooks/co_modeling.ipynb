{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import main\n",
    "from prepare import prep_readme_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/prepared/clean_readmes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'watchers': 'watchers_num',\n",
    "                   'stars': 'stars_num',\n",
    "                   'forks': 'forks_num',\n",
    "                   'commits': 'commits_num'},\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform text data using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(df.words)\n",
    "X = pd.concat([df[['watchers_num', 'stars_num', 'forks_num', 'commits_num']], pd.DataFrame(X_tfidf.todense(), columns=tfidf.get_feature_names())], axis=1)\n",
    "y = df.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<589x25888 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 89418 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(df.words)\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_validate, X_test, y_train_validate, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train_validate, y_train_validate, stratify=y_train_validate, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 25892)\n",
      "(353,)\n",
      "(118, 25892)\n",
      "(118,)\n",
      "(118, 25892)\n",
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_validate.shape)\n",
    "print(y_validate.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numeric_columns(X_train, X_validate, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Concatenate scaled test data onto sparse matrix\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train[['watchers_num', 'stars_num',\n",
    "                                                                'forks_num', 'commits_num']]))\n",
    "    X_train_scaled.rename(columns={0: 'watchers_num',\n",
    "                                   1: 'stars_num',\n",
    "                                   2: 'forks_num',\n",
    "                                   3: 'commits_num'},\n",
    "                         inplace=True)\n",
    "\n",
    "    X_train_scaled.index = X_train.index\n",
    "    X_train.drop(columns=['watchers_num', 'stars_num', 'forks_num', 'commits_num'], inplace=True)\n",
    "    X_train = pd.concat([X_train, X_train_scaled], axis=1)\n",
    "    \n",
    "\n",
    "    # Concatenate scaled test data onto sparse matrix\n",
    "    X_validate_scaled = pd.DataFrame(scaler.transform(X_validate[['watchers_num', 'stars_num',\n",
    "                                                            'forks_num', 'commits_num']]))\n",
    "    X_validate_scaled.rename(columns={0: 'watchers_num',\n",
    "                                   1: 'stars_num',\n",
    "                                   2: 'forks_num',\n",
    "                                   3: 'commits_num'},\n",
    "                         inplace=True)\n",
    "    \n",
    "    X_validate_scaled.index = X_validate.index\n",
    "    X_validate.drop(columns=['watchers_num', 'stars_num', 'forks_num', 'commits_num'], inplace=True)\n",
    "    X_validate = pd.concat([X_validate, X_validate_scaled], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Concatenate scaled test data onto sparse matrix\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test[['watchers_num', 'stars_num',\n",
    "                                                          'forks_num', 'commits_num']]))\n",
    "    \n",
    "    X_test_scaled.rename(columns={0: 'watchers_num',\n",
    "                                  1: 'stars_num',\n",
    "                                  2: 'forks_num',\n",
    "                                  3: 'commits_num'},\n",
    "                         inplace=True)\n",
    "\n",
    "    X_test_scaled.index = X_test.index\n",
    "    X_test.drop(columns=['watchers_num', 'stars_num', 'forks_num', 'commits_num'], inplace=True)\n",
    "    X_test = pd.concat([X_test, X_test_scaled], axis=1)\n",
    "    \n",
    "    return X_train, X_validate, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validate, X_test = scale_numeric_columns(X_train, X_validate, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "svm_params = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "boost_params = {'learning_rate': [0.0001, 0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7372881355932204"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_search = GridSearchCV(LogisticRegression(), logit_params, cv=5)\n",
    "\n",
    "logit_grid_search.fit(X_train, y_train)\n",
    "\n",
    "logit_grid_search.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# svm_grid_search = GridSearchCV(SVC(), svm_params, cv=5)\n",
    "# svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # svm_grid_search.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6440677966101694"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaus = GaussianNB()\n",
    "gaus.fit(X_train, y_train)\n",
    "gaus.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7372881355932204"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RidgeClassifierCV()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_grid_search = GridSearchCV(GradientBoostingClassifier(), boost_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boost_grid_search.fit(X_train, y_train)\n",
    "# boost_grid_search.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7288135593220338"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = RandomForestClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "logit = LogisticRegression(C=10).fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = logit.predict(X_train)\n",
    "validate['predicted'] = logit.predict(X_validate)\n",
    "test['predicted'] = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.15%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      C++  Java  JavaScript  Python\n",
      "predicted                                \n",
      "C++          89     1           0       1\n",
      "Java          1    86           0       0\n",
      "JavaScript    0     0          91       0\n",
      "Python        0     0           0      84\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C++       0.98      0.99      0.98        90\n",
      "        Java       0.99      0.99      0.99        87\n",
      "  JavaScript       1.00      1.00      1.00        91\n",
      "      Python       1.00      0.99      0.99        85\n",
      "\n",
      "    accuracy                           0.99       353\n",
      "   macro avg       0.99      0.99      0.99       353\n",
      "weighted avg       0.99      0.99      0.99       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.73%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      C++  Java  JavaScript  Python\n",
      "predicted                                \n",
      "C++          23     6           2       1\n",
      "Java          1    15           1       2\n",
      "JavaScript    3     1          26       2\n",
      "Python        3     7           2      23\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C++       0.72      0.77      0.74        30\n",
      "        Java       0.79      0.52      0.62        29\n",
      "  JavaScript       0.81      0.84      0.83        31\n",
      "      Python       0.66      0.82      0.73        28\n",
      "\n",
      "    accuracy                           0.74       118\n",
      "   macro avg       0.74      0.74      0.73       118\n",
      "weighted avg       0.75      0.74      0.73       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate.actual, validate.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(validate.predicted, validate.actual))\n",
    "print('---')\n",
    "print(classification_report(validate.actual, validate.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.03%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      C++  Java  JavaScript  Python\n",
      "predicted                                \n",
      "C++          22     7           3       2\n",
      "Java          3    15           1       0\n",
      "JavaScript    2     4          23       1\n",
      "Python        3     3           4      25\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C++       0.65      0.73      0.69        30\n",
      "        Java       0.79      0.52      0.62        29\n",
      "  JavaScript       0.77      0.74      0.75        31\n",
      "      Python       0.71      0.89      0.79        28\n",
      "\n",
      "    accuracy                           0.72       118\n",
      "   macro avg       0.73      0.72      0.72       118\n",
      "weighted avg       0.73      0.72      0.71       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
